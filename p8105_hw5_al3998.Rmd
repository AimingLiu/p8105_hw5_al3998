---
title: "p8105_hw5_al3998"
author: "AimingLiu"
date: "10/31/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      fig.width = 8, 
                      fig.height = 6,
                      out.width = "90%"
)
library(tidyverse)
library(dplyr)
library(rvest)
library(purrr)
library(broom)
library(patchwork)

set.seed(10)
```

```{r}
set.seed(10)
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()  
```
## Problem 1
### write the function

```{r}
  NAmean = function(x){
    if (is.numeric(x)){
    replace(x, is.na(x), mean(x, na.rm = TRUE))
    }else if(is.character(x)){
     replace(x, is.na(x), "virginica") 
    }
  }
```

```{r}
 output = vector("list", length = 5)
  for(i in 1:5){
    output[[i]] = NAmean(iris_with_missing[[i]])
  }
  output = map(iris_with_missing, NAmean)
  output
```

## Problem 2
```{r message=FALSE,warning = FALSE}
file_list = as.data.frame(list.files(path = "./data/", pattern="*.csv")) 
 colnames(file_list) =  "file_name"
```

```{r message=FALSE,warning = FALSE}
file_path =  "./data/"
read_file = function(file_name){
         read_csv(paste0(file_path, file_name))
         
}

output = purrr::map(file_list$file_name, read_file)

```

```{r message=FALSE,warning = FALSE}
file_nest = 
  file_list %>% 
  mutate(data = purrr::map(file_list$file_name, read_file)) %>% 
  unnest()
```

```{r message=FALSE,warning = FALSE}
  file_tidy = file_nest %>% 
  pivot_longer(week_1:week_8,
               names_to = "week",
               values_to = "data") %>% 
  mutate(file_name = str_remove(file_name, ".csv"),
         week = str_remove(week, "week_")) %>% 
  separate(file_name,into = c("group", "subject_id"), sep = "_") %>% 
  mutate(group = recode(group,"con"="control","exp" = "experimental"))
  ggplot(file_tidy,aes(x= week,y = data,color =subject_id,group = subject_id))+
  geom_point()+
  geom_line()+
  labs(
     title = "  observations on each subject over time",
     x = "week",
     y = "data"
  )+ theme(legend.position = "bottom")+
  facet_grid(~group)
```

The fluctuation of data between different weeks are larger in experiental group than in control group.

And we can notice that the data in week 1 and week 8 in control group are almost the same.But in experimental group,from week 1 to week 8,the data become larger which means that intervening measure may be useful.

# Problem 3

## writen the function
```{r}
sim_regression = function(n = 30, beta0 = 2, beta1) {
  sim_data = tibble(
    x = rnorm(30, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(30, 0, sqrt(50))
  )
  ls_fit = lm(y ~ x, data = sim_data)
  ls_tidy = broom::tidy(ls_fit)
  tibble(
   beta1_hat = ls_tidy$estimate[2],
   p_value = ls_tidy$p.value[2])
}


```

Generate 10000 datasets from the model
```{r}
set.seed(10)
output_b1 = rerun(10000, sim_regression(beta1 = 0)) %>% 
 bind_rows()

head(output_b1)
```

Repeat the above for β1={1,2,3,4,5,6}
```{r}
beta_list = list("beta1_1"  = 1, 
                 "beta1_2"  = 2, 
                 "beta1_3"  = 3, 
                 "beta1_4"  = 4,
                 "beta1_5"  = 5,
                 "beta1_6"  = 6)
output = vector("list", length = 6)

for (i in 1:6) {
  output[[i]] = rerun(10000, sim_regression(beta1 = beta_list[[i]])) %>% 
    bind_rows
}
```

```{r}
beta_results = 
  tibble(beta1_value = c(1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = beta1_value, ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)

  head(beta_results)
```

```{r}
  beta_sig = beta_results %>% 
  group_by(beta1_value) %>% 
  filter(p_value < 0.05) %>% 
  group_by(beta1_value) %>% 
  mutate(power = n()/10000) 
  plot = beta_sig %>% 
  select(beta1_value,power) %>% 
  distinct() 
  ggplot(plot,aes(x = beta1_value,y = power,fill = beta1_value))+
    geom_col()+
    labs(
    title = "Plot about the power about different beta1 value",
    x = "value of beta1",
    y = "power")  
```

We can see from the graphic,when the difference between beta1 and 0 get larger,the value of power get larger and it is easier for us to reject the null.And the effect size gets larger,the power gets larger.


### Make a plot showing the average estimate of beta1 and the true value of beta1 

```{r}
  beta_mean = beta_results %>% 
  group_by(beta1_value) %>% 
  mutate(mean = mean(beta1_hat)) 
  plot1 = ggplot(beta_mean,aes(x = beta1_value,y = mean))+
    geom_line()+
    geom_point()+
    labs(
    title = "average estimate of beta1",
    x = "value of beta1",
    y = "average estimate of beta1")  
   plot1    
```

### Make a second plot on the average estimate of beta1 only in samples for which the null was rejected  and the true value of beta1
 
```{r}
 beta_sig_ave = beta_sig %>% 
 mutate(mean_sig = mean(beta1_hat)) 
 plot2 = ggplot(beta_sig_ave,aes(x = beta1_value,y = mean_sig))+
    geom_line()+
    geom_point()+
    labs(
    title = "average estimate of beta1 only in samples for which the null was rejected",
    x = "value of beta1",
    y = "average estimate of beta1") 
  plot2

```

### Making a plot combining plot1 and plot2

```{r}
beta_sig_ave = beta_sig %>% 
 mutate(mean_sig = mean(beta1_hat)) 
 plot3 =plot1+
   geom_line(data = beta_sig_ave,aes(x = beta1_value,y = mean_sig),color = "red")+
   geom_point(data =beta_sig_ave,aes(x = beta1_value,y = mean_sig),color = "red")+
    labs(
    title = "average estimate of beta1 in two different conditions",
    x = "value of beta1",
    y = "average estimate of beta1") 
  plot3

```


The sample average of β̂1 across tests for which the null is rejected approximately is not equal to the true value of β1.
Because when we reject the null hypothesis,we consider that β̂1 we got is significant different from  β1,and then we calculate the mean,it can not be equal to the value of  beta1.
